{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DenseNet.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"1o_qmksLPIVj","colab_type":"code","outputId":"3967bf16-ed59-4ffe-856d-4c9e1e591b8d","executionInfo":{"status":"ok","timestamp":1578536257184,"user_tz":-540,"elapsed":2170,"user":{"displayName":"최동식","photoUrl":"","userId":"04265322925960261071"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","import torchvision.datasets as dset\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","import torchvision.models as models\n","from torchvision import datasets, transforms\n","import time\n","import sys\n","import math\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","batch_size=64\n","learning_rate = 0.1\n","layers = 121\n","transform_train = transforms.Compose([ \n","                                      transforms.RandomCrop(32, padding=4), \n","                                      transforms.RandomHorizontalFlip(), \n","                                      transforms.ToTensor(), \n","                                      ]) \n","transform_test = transforms.Compose([ \n","                                     transforms.ToTensor(), \n","                                     ]) \n","train_loader = torch.utils.data.DataLoader( \n","    datasets.CIFAR10('../data',train=True,download=True,transform=transform_train), \n","    batch_size=batch_size,shuffle=True \n","    ) \n","test_loader = torch.utils.data.DataLoader( \n","    datasets.CIFAR10('../data',train=False,transform=transform_test), \n","    batch_size=batch_size,shuffle=True )\n","\n","\n","class BasicBlock(nn.Module):\n","    def __init__(self, in_planes, out_planes, dropRate=0.0):\n","        super(BasicBlock, self).__init__()\n","        self.bn1 = nn.BatchNorm2d(in_planes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=1,\n","                               padding=1, bias=False)\n","        self.droprate = dropRate\n","    def forward(self, x):\n","        out = self.conv1(self.relu(self.bn1(x)))\n","        if self.droprate > 0:\n","            out = F.dropout(out, p=self.droprate, training=self.training)\n","        return torch.cat([x, out], 1)\n","\n","class BottleneckBlock(nn.Module):\n","    def __init__(self, in_planes, out_planes, dropRate=0.0):\n","        super(BottleneckBlock, self).__init__()\n","        inter_planes = out_planes * 4\n","        self.bn1 = nn.BatchNorm2d(in_planes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv1 = nn.Conv2d(in_planes, inter_planes, kernel_size=1, stride=1,\n","                               padding=0, bias=False)\n","        self.bn2 = nn.BatchNorm2d(inter_planes)\n","        self.conv2 = nn.Conv2d(inter_planes, out_planes, kernel_size=3, stride=1,\n","                               padding=1, bias=False)\n","        self.droprate = dropRate\n","    def forward(self, x):\n","        out = self.conv1(self.relu(self.bn1(x)))\n","        if self.droprate > 0:\n","            out = F.dropout(out, p=self.droprate, inplace=False, training=self.training)\n","        out = self.conv2(self.relu(self.bn2(out)))\n","        if self.droprate > 0:\n","            out = F.dropout(out, p=self.droprate, inplace=False, training=self.training)\n","        return torch.cat([x, out], 1)\n","\n","class TransitionBlock(nn.Module):\n","    def __init__(self, in_planes, out_planes, dropRate=0.0):\n","        super(TransitionBlock, self).__init__()\n","        self.bn1 = nn.BatchNorm2d(in_planes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1,\n","                               padding=0, bias=False)\n","        self.droprate = dropRate\n","    def forward(self, x):\n","        out = self.conv1(self.relu(self.bn1(x)))\n","        if self.droprate > 0:\n","            out = F.dropout(out, p=self.droprate, inplace=False, training=self.training)\n","        return F.avg_pool2d(out, 2)\n","\n","class DenseBlock(nn.Module):\n","    def __init__(self, nb_layers, in_planes, growth_rate, block, dropRate=0.0):\n","        super(DenseBlock, self).__init__()\n","        self.layer = self._make_layer(block, in_planes, growth_rate, nb_layers, dropRate)\n","    def _make_layer(self, block, in_planes, growth_rate, nb_layers, dropRate):\n","        layers = []\n","        for i in range(nb_layers):\n","            layers.append(block(in_planes+i*growth_rate, growth_rate, dropRate))\n","        return nn.Sequential(*layers)\n","    def forward(self, x):\n","        return self.layer(x)\n","\n","class DenseNet(nn.Module):\n","    def __init__(self, depth, num_classes, growth_rate=12,\n","                 reduction=0.5, bottleneck=True, dropRate=0.0):\n","        super(DenseNet, self).__init__()\n","        in_planes = 2 * growth_rate\n","        n = (depth - 4) / 3\n","        if bottleneck == True:\n","            n = n/2\n","            block = BottleneckBlock\n","        else:\n","            block = BasicBlock\n","        n = int(n)\n","        # 1st conv before any dense block\n","        self.conv1 = nn.Conv2d(3, in_planes, kernel_size=3, stride=1,\n","                               padding=1, bias=False)\n","        # 1st block\n","        self.block1 = DenseBlock(n, in_planes, growth_rate, block, dropRate)\n","        in_planes = int(in_planes+n*growth_rate)\n","        self.trans1 = TransitionBlock(in_planes, int(math.floor(in_planes*reduction)), dropRate=dropRate)\n","        in_planes = int(math.floor(in_planes*reduction))\n","        # 2nd block\n","        self.block2 = DenseBlock(n, in_planes, growth_rate, block, dropRate)\n","        in_planes = int(in_planes+n*growth_rate)\n","        self.trans2 = TransitionBlock(in_planes, int(math.floor(in_planes*reduction)), dropRate=dropRate)\n","        in_planes = int(math.floor(in_planes*reduction))\n","        # 3rd block\n","        self.block3 = DenseBlock(n, in_planes, growth_rate, block, dropRate)\n","        in_planes = int(in_planes+n*growth_rate)\n","        # global average pooling and classifier\n","        self.bn1 = nn.BatchNorm2d(in_planes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.fc = nn.Linear(in_planes, num_classes)\n","        self.in_planes = in_planes\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","                m.weight.data.normal_(0, math.sqrt(2. / n))\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","            elif isinstance(m, nn.Linear):\n","                m.bias.data.zero_()\n","    def forward(self, x):\n","        out = self.conv1(x)\n","        out = self.trans1(self.block1(out))\n","        out = self.trans2(self.block2(out))\n","        out = self.block3(out)\n","        out = self.relu(self.bn1(out))\n","        out = F.avg_pool2d(out, 8)\n","        out = out.view(-1, self.in_planes)\n","        return self.fc(out)\n","\n","\n","model = DenseNet(layers,10,growth_rate=12,dropRate = 0.0)\n","model = model.to(device)\n","criterion = nn.CrossEntropyLoss().to(device)\n","optimizer = torch.optim.SGD(model.parameters(),lr = learning_rate,\n","                            momentum=0.9,nesterov=True,weight_decay=1e-4)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kjg1XzX7y7Gp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"1eb4c6fd-a847-429e-896e-231608355b8b","executionInfo":{"status":"ok","timestamp":1578538665506,"user_tz":-540,"elapsed":2406206,"user":{"displayName":"최동식","photoUrl":"","userId":"04265322925960261071"}}},"source":["def train(train_loader,model,criterion,optimizer,epoch):\n","    model.train()\n","    trn_loss = 0.0\n","    start = time.time()\n","    for i, (input,target) in enumerate(train_loader):\n","        target = target.to(device)\n","        input = input.to(device)\n","        \n","        output = model(input)\n","        loss = criterion(output,target)\n","        \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        trn_loss += loss.data\n","        if(i%100 == 0):\n","            end=time.time()\n","            print(\"loss in epoch %d , step %d : %f time : %.3f 's\" % (epoch, i,trn_loss/100, (end-start))) #loss.data[0]loss.item()\n","            start=time.time()\n","            trn_loss = 0.0\n","\n","def test(test_loader,model,criterion,epoch):\n","    model.eval()\n","    \n","    correct = 0\n","    \n","    \n","    for i, (input,target) in enumerate(test_loader):\n","        target = target.to(device)\n","        input = input.to(device)\n","        \n","        output = model(input)\n","        loss = criterion(output,target)\n","        \n","        pred = output.data.max(1, keepdim=True)[1]\n","        correct += pred.eq(target.data.view_as(pred)).cpu().float().sum()\n","    \n","    print(\"Accuracy in epoch %d : %f \" % (epoch,100.0*correct/len(test_loader.dataset)))\n","\n","\n","def adjust_lr(optimizer, epoch, learning_rate):\n","    if epoch==150 :\n","        learning_rate*=0.1\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = learning_rate\n","fstart = time.time()\n","for epoch in range(0,20):\n","    adjust_lr(optimizer,epoch,learning_rate)\n","    train(train_loader,model,criterion,optimizer,epoch)\n","    test(test_loader,model,criterion,epoch)\n","fend = time.time()\n","print(\"%.3f 's\"% (fend - fstart))"],"execution_count":22,"outputs":[{"output_type":"stream","text":["loss in epoch 0 , step 0 : 0.023152 time : 0.155 's\n","loss in epoch 0 , step 100 : 1.959336 time : 14.569 's\n","loss in epoch 0 , step 200 : 1.664730 time : 14.582 's\n","loss in epoch 0 , step 300 : 1.486180 time : 14.581 's\n","loss in epoch 0 , step 400 : 1.365689 time : 14.586 's\n","loss in epoch 0 , step 500 : 1.229280 time : 14.585 's\n","loss in epoch 0 , step 600 : 1.145364 time : 14.577 's\n","loss in epoch 0 , step 700 : 1.094166 time : 14.579 's\n","Accuracy in epoch 0 : 59.330002 \n","loss in epoch 1 , step 0 : 0.011738 time : 0.148 's\n","loss in epoch 1 , step 100 : 0.985535 time : 14.557 's\n","loss in epoch 1 , step 200 : 0.930653 time : 14.583 's\n","loss in epoch 1 , step 300 : 0.923074 time : 14.583 's\n","loss in epoch 1 , step 400 : 0.862954 time : 14.570 's\n","loss in epoch 1 , step 500 : 0.843441 time : 14.589 's\n","loss in epoch 1 , step 600 : 0.811860 time : 14.582 's\n","loss in epoch 1 , step 700 : 0.791787 time : 14.587 's\n","Accuracy in epoch 1 : 67.599998 \n","loss in epoch 2 , step 0 : 0.008283 time : 0.147 's\n","loss in epoch 2 , step 100 : 0.731417 time : 14.595 's\n","loss in epoch 2 , step 200 : 0.683665 time : 14.565 's\n","loss in epoch 2 , step 300 : 0.724429 time : 14.585 's\n","loss in epoch 2 , step 400 : 0.693371 time : 14.566 's\n","loss in epoch 2 , step 500 : 0.678962 time : 14.594 's\n","loss in epoch 2 , step 600 : 0.642670 time : 14.582 's\n","loss in epoch 2 , step 700 : 0.634866 time : 14.572 's\n","Accuracy in epoch 2 : 65.040001 \n","loss in epoch 3 , step 0 : 0.006548 time : 0.147 's\n","loss in epoch 3 , step 100 : 0.586520 time : 14.580 's\n","loss in epoch 3 , step 200 : 0.606071 time : 14.584 's\n","loss in epoch 3 , step 300 : 0.570739 time : 14.592 's\n","loss in epoch 3 , step 400 : 0.584581 time : 14.600 's\n","loss in epoch 3 , step 500 : 0.562698 time : 14.568 's\n","loss in epoch 3 , step 600 : 0.550629 time : 14.583 's\n","loss in epoch 3 , step 700 : 0.557663 time : 14.590 's\n","Accuracy in epoch 3 : 75.519997 \n","loss in epoch 4 , step 0 : 0.005563 time : 0.147 's\n","loss in epoch 4 , step 100 : 0.517566 time : 14.572 's\n","loss in epoch 4 , step 200 : 0.505353 time : 14.584 's\n","loss in epoch 4 , step 300 : 0.515948 time : 14.577 's\n","loss in epoch 4 , step 400 : 0.507906 time : 14.586 's\n","loss in epoch 4 , step 500 : 0.517768 time : 14.585 's\n","loss in epoch 4 , step 600 : 0.508719 time : 14.593 's\n","loss in epoch 4 , step 700 : 0.497043 time : 14.587 's\n","Accuracy in epoch 4 : 78.300003 \n","loss in epoch 5 , step 0 : 0.004618 time : 0.148 's\n","loss in epoch 5 , step 100 : 0.468452 time : 14.585 's\n","loss in epoch 5 , step 200 : 0.448210 time : 14.586 's\n","loss in epoch 5 , step 300 : 0.475132 time : 14.588 's\n","loss in epoch 5 , step 400 : 0.457047 time : 14.578 's\n","loss in epoch 5 , step 500 : 0.472659 time : 14.582 's\n","loss in epoch 5 , step 600 : 0.473691 time : 14.588 's\n","loss in epoch 5 , step 700 : 0.470102 time : 14.584 's\n","Accuracy in epoch 5 : 80.000000 \n","loss in epoch 6 , step 0 : 0.005348 time : 0.148 's\n","loss in epoch 6 , step 100 : 0.440854 time : 14.562 's\n","loss in epoch 6 , step 200 : 0.438979 time : 14.573 's\n","loss in epoch 6 , step 300 : 0.455643 time : 14.586 's\n","loss in epoch 6 , step 400 : 0.422150 time : 14.585 's\n","loss in epoch 6 , step 500 : 0.450822 time : 14.602 's\n","loss in epoch 6 , step 600 : 0.438075 time : 14.599 's\n","loss in epoch 6 , step 700 : 0.435529 time : 14.578 's\n","Accuracy in epoch 6 : 79.410004 \n","loss in epoch 7 , step 0 : 0.004587 time : 0.149 's\n","loss in epoch 7 , step 100 : 0.417625 time : 14.568 's\n","loss in epoch 7 , step 200 : 0.437287 time : 14.601 's\n","loss in epoch 7 , step 300 : 0.396496 time : 14.579 's\n","loss in epoch 7 , step 400 : 0.423450 time : 14.579 's\n","loss in epoch 7 , step 500 : 0.396647 time : 14.593 's\n","loss in epoch 7 , step 600 : 0.412652 time : 14.585 's\n","loss in epoch 7 , step 700 : 0.412906 time : 14.597 's\n","Accuracy in epoch 7 : 83.250000 \n","loss in epoch 8 , step 0 : 0.003749 time : 0.148 's\n","loss in epoch 8 , step 100 : 0.370080 time : 14.573 's\n","loss in epoch 8 , step 200 : 0.388791 time : 14.589 's\n","loss in epoch 8 , step 300 : 0.380689 time : 14.595 's\n","loss in epoch 8 , step 400 : 0.388978 time : 14.583 's\n","loss in epoch 8 , step 500 : 0.399399 time : 14.600 's\n","loss in epoch 8 , step 600 : 0.392638 time : 14.588 's\n","loss in epoch 8 , step 700 : 0.378267 time : 14.596 's\n","Accuracy in epoch 8 : 80.300003 \n","loss in epoch 9 , step 0 : 0.003659 time : 0.147 's\n","loss in epoch 9 , step 100 : 0.343821 time : 14.525 's\n","loss in epoch 9 , step 200 : 0.341411 time : 14.508 's\n","loss in epoch 9 , step 300 : 0.369621 time : 14.586 's\n","loss in epoch 9 , step 400 : 0.387699 time : 14.581 's\n","loss in epoch 9 , step 500 : 0.385727 time : 14.588 's\n","loss in epoch 9 , step 600 : 0.375492 time : 14.576 's\n","loss in epoch 9 , step 700 : 0.379207 time : 14.592 's\n","Accuracy in epoch 9 : 83.339996 \n","loss in epoch 10 , step 0 : 0.002958 time : 0.147 's\n","loss in epoch 10 , step 100 : 0.352752 time : 14.555 's\n","loss in epoch 10 , step 200 : 0.345023 time : 14.592 's\n","loss in epoch 10 , step 300 : 0.366478 time : 14.559 's\n","loss in epoch 10 , step 400 : 0.360694 time : 14.491 's\n","loss in epoch 10 , step 500 : 0.355202 time : 14.532 's\n","loss in epoch 10 , step 600 : 0.361897 time : 14.500 's\n","loss in epoch 10 , step 700 : 0.359694 time : 14.518 's\n","Accuracy in epoch 10 : 83.339996 \n","loss in epoch 11 , step 0 : 0.002204 time : 0.148 's\n","loss in epoch 11 , step 100 : 0.338052 time : 14.503 's\n","loss in epoch 11 , step 200 : 0.317721 time : 14.561 's\n","loss in epoch 11 , step 300 : 0.348832 time : 14.576 's\n","loss in epoch 11 , step 400 : 0.361619 time : 14.506 's\n","loss in epoch 11 , step 500 : 0.333306 time : 14.536 's\n","loss in epoch 11 , step 600 : 0.358298 time : 14.539 's\n","loss in epoch 11 , step 700 : 0.346092 time : 14.487 's\n","Accuracy in epoch 11 : 83.129997 \n","loss in epoch 12 , step 0 : 0.002351 time : 0.147 's\n","loss in epoch 12 , step 100 : 0.324410 time : 14.502 's\n","loss in epoch 12 , step 200 : 0.337104 time : 14.553 's\n","loss in epoch 12 , step 300 : 0.333386 time : 14.603 's\n","loss in epoch 12 , step 400 : 0.339595 time : 14.569 's\n","loss in epoch 12 , step 500 : 0.342184 time : 14.516 's\n","loss in epoch 12 , step 600 : 0.346354 time : 14.512 's\n","loss in epoch 12 , step 700 : 0.313925 time : 14.571 's\n","Accuracy in epoch 12 : 78.089996 \n","loss in epoch 13 , step 0 : 0.002291 time : 0.147 's\n","loss in epoch 13 , step 100 : 0.316665 time : 14.525 's\n","loss in epoch 13 , step 200 : 0.317249 time : 14.539 's\n","loss in epoch 13 , step 300 : 0.316396 time : 14.493 's\n","loss in epoch 13 , step 400 : 0.318675 time : 14.565 's\n","loss in epoch 13 , step 500 : 0.334079 time : 14.530 's\n","loss in epoch 13 , step 600 : 0.334509 time : 14.491 's\n","loss in epoch 13 , step 700 : 0.316776 time : 14.563 's\n","Accuracy in epoch 13 : 84.449997 \n","loss in epoch 14 , step 0 : 0.002963 time : 0.148 's\n","loss in epoch 14 , step 100 : 0.307468 time : 14.522 's\n","loss in epoch 14 , step 200 : 0.296690 time : 14.561 's\n","loss in epoch 14 , step 300 : 0.308749 time : 14.479 's\n","loss in epoch 14 , step 400 : 0.323654 time : 14.553 's\n","loss in epoch 14 , step 500 : 0.313851 time : 14.544 's\n","loss in epoch 14 , step 600 : 0.332279 time : 14.495 's\n","loss in epoch 14 , step 700 : 0.327568 time : 14.555 's\n","Accuracy in epoch 14 : 84.000000 \n","loss in epoch 15 , step 0 : 0.004504 time : 0.147 's\n","loss in epoch 15 , step 100 : 0.323516 time : 14.513 's\n","loss in epoch 15 , step 200 : 0.307010 time : 14.488 's\n","loss in epoch 15 , step 300 : 0.308000 time : 14.550 's\n","loss in epoch 15 , step 400 : 0.319101 time : 14.538 's\n","loss in epoch 15 , step 500 : 0.326403 time : 14.502 's\n","loss in epoch 15 , step 600 : 0.310595 time : 14.526 's\n","loss in epoch 15 , step 700 : 0.310298 time : 14.502 's\n","Accuracy in epoch 15 : 82.440002 \n","loss in epoch 16 , step 0 : 0.003036 time : 0.146 's\n","loss in epoch 16 , step 100 : 0.274535 time : 14.493 's\n","loss in epoch 16 , step 200 : 0.299044 time : 14.558 's\n","loss in epoch 16 , step 300 : 0.301057 time : 14.539 's\n","loss in epoch 16 , step 400 : 0.306470 time : 14.502 's\n","loss in epoch 16 , step 500 : 0.320970 time : 14.515 's\n","loss in epoch 16 , step 600 : 0.305109 time : 14.523 's\n","loss in epoch 16 , step 700 : 0.313705 time : 14.589 's\n","Accuracy in epoch 16 : 81.410004 \n","loss in epoch 17 , step 0 : 0.003926 time : 0.147 's\n","loss in epoch 17 , step 100 : 0.278799 time : 14.526 's\n","loss in epoch 17 , step 200 : 0.285681 time : 14.482 's\n","loss in epoch 17 , step 300 : 0.299628 time : 14.566 's\n","loss in epoch 17 , step 400 : 0.300556 time : 14.597 's\n","loss in epoch 17 , step 500 : 0.297935 time : 14.606 's\n","loss in epoch 17 , step 600 : 0.309651 time : 14.516 's\n","loss in epoch 17 , step 700 : 0.318829 time : 14.511 's\n","Accuracy in epoch 17 : 80.230003 \n","loss in epoch 18 , step 0 : 0.002359 time : 0.147 's\n","loss in epoch 18 , step 100 : 0.280822 time : 14.504 's\n","loss in epoch 18 , step 200 : 0.256752 time : 14.531 's\n","loss in epoch 18 , step 300 : 0.294654 time : 14.488 's\n","loss in epoch 18 , step 400 : 0.288577 time : 14.521 's\n","loss in epoch 18 , step 500 : 0.320808 time : 14.510 's\n","loss in epoch 18 , step 600 : 0.292918 time : 14.590 's\n","loss in epoch 18 , step 700 : 0.286552 time : 14.599 's\n","Accuracy in epoch 18 : 86.150002 \n","loss in epoch 19 , step 0 : 0.002409 time : 0.148 's\n","loss in epoch 19 , step 100 : 0.268614 time : 14.491 's\n","loss in epoch 19 , step 200 : 0.276805 time : 14.556 's\n","loss in epoch 19 , step 300 : 0.309203 time : 14.523 's\n","loss in epoch 19 , step 400 : 0.279005 time : 14.518 's\n","loss in epoch 19 , step 500 : 0.292835 time : 14.542 's\n","loss in epoch 19 , step 600 : 0.282695 time : 14.490 's\n","loss in epoch 19 , step 700 : 0.289723 time : 14.544 's\n","Accuracy in epoch 19 : 83.849998 \n","2405.097 's\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iYhEBgdi1VMm","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}